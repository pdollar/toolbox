---------------------------------------------------------------------------
Training stage 0
Sampled 1237 windows from 614 images.
Done sampling windows (time=5s).
Extracting features... done (time=1s).
Computing lambdas... done (time=7s).
Sampled 5000 windows from 256 images.
Done sampling windows (time=3s).
Extracting features... done (time=2s).
Training AdaBoost: nWeak= 32 nFtrs=5120 pos=2474 neg=5000
 i=  16 alpha=0.426 err=0.299 loss=9.61e-02
 i=  32 alpha=0.450 err=0.289 loss=2.17e-02
Done training err=0.0018 fp=0.0020 fn=0.0016 (t=0.4s).
Done training stage 0 (time=19s).
---------------------------------------------------------------------------
Training stage 1
Sampled 5000 windows from 384 images.
Done sampling windows (time=4s).
Extracting features... done (time=2s).
Training AdaBoost: nWeak=128 nFtrs=5120 pos=2474 neg=10000
 i=  16 alpha=0.316 err=0.347 loss=2.59e-01
 i=  32 alpha=0.316 err=0.347 loss=1.22e-01
 i=  48 alpha=0.312 err=0.349 loss=6.26e-02
 i=  64 alpha=0.233 err=0.385 loss=3.45e-02
 i=  80 alpha=0.265 err=0.370 loss=1.90e-02
 i=  96 alpha=0.255 err=0.375 loss=1.11e-02
 i= 112 alpha=0.265 err=0.371 loss=6.34e-03
 i= 128 alpha=0.277 err=0.365 loss=3.54e-03
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=1.0s).
Done training stage 1 (time=8s).
---------------------------------------------------------------------------
Training stage 2
Sampled 5000 windows from 1216 images.
Done sampling windows (time=8s).
Extracting features... done (time=2s).
Training AdaBoost: nWeak=512 nFtrs=5120 pos=2474 neg=10000
 i=  16 alpha=0.285 err=0.361 loss=3.96e-01
 i=  32 alpha=0.252 err=0.377 loss=2.45e-01
 i=  48 alpha=0.211 err=0.396 loss=1.59e-01
 i=  64 alpha=0.219 err=0.392 loss=1.08e-01
 i=  80 alpha=0.200 err=0.401 loss=7.28e-02
 i=  96 alpha=0.199 err=0.402 loss=5.03e-02
 i= 112 alpha=0.219 err=0.392 loss=3.48e-02
 i= 128 alpha=0.233 err=0.385 loss=2.38e-02
 i= 144 alpha=0.219 err=0.392 loss=1.61e-02
 i= 160 alpha=0.201 err=0.401 loss=1.10e-02
 i= 176 alpha=0.237 err=0.384 loss=7.71e-03
 i= 192 alpha=0.213 err=0.395 loss=5.27e-03
 i= 208 alpha=0.202 err=0.400 loss=3.59e-03
 i= 224 alpha=0.205 err=0.399 loss=2.55e-03
 i= 240 alpha=0.221 err=0.391 loss=1.76e-03
 i= 256 alpha=0.233 err=0.385 loss=1.23e-03
 i= 272 alpha=0.216 err=0.393 loss=8.53e-04
 i= 288 alpha=0.208 err=0.398 loss=5.83e-04
 i= 304 alpha=0.217 err=0.393 loss=4.10e-04
 i= 320 alpha=0.220 err=0.392 loss=2.89e-04
 i= 336 alpha=0.216 err=0.394 loss=2.03e-04
 i= 352 alpha=0.227 err=0.388 loss=1.45e-04
 i= 368 alpha=0.232 err=0.386 loss=1.00e-04
 i= 384 alpha=0.215 err=0.394 loss=7.00e-05
 i= 400 alpha=0.216 err=0.393 loss=4.92e-05
 i= 416 alpha=0.200 err=0.401 loss=3.49e-05
 i= 432 alpha=0.206 err=0.398 loss=2.47e-05
 i= 448 alpha=0.210 err=0.397 loss=1.69e-05
 i= 464 alpha=0.173 err=0.414 loss=1.24e-05
 i= 480 alpha=0.192 err=0.405 loss=8.81e-06
 i= 496 alpha=0.233 err=0.385 loss=6.20e-06
 i= 512 alpha=0.218 err=0.393 loss=4.39e-06
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=2.9s).
Done training stage 2 (time=14s).
---------------------------------------------------------------------------
Training stage 3
Sampled 710 windows from 1218 images.
Done sampling windows (time=7s).
Extracting features... done (time=0s).
Training AdaBoost: nWeak=2048 nFtrs=5120 pos=2474 neg=10000
 i=  16 alpha=0.231 err=0.386 loss=4.11e-01
 i=  32 alpha=0.218 err=0.393 loss=2.70e-01
 i=  48 alpha=0.199 err=0.402 loss=1.80e-01
 i=  64 alpha=0.209 err=0.397 loss=1.26e-01
 i=  80 alpha=0.199 err=0.402 loss=8.92e-02
 i=  96 alpha=0.206 err=0.399 loss=6.44e-02
 i= 112 alpha=0.233 err=0.386 loss=4.58e-02
 i= 128 alpha=0.200 err=0.401 loss=3.29e-02
 i= 144 alpha=0.198 err=0.402 loss=2.31e-02
 i= 160 alpha=0.177 err=0.412 loss=1.70e-02
 i= 176 alpha=0.193 err=0.405 loss=1.25e-02
 i= 192 alpha=0.187 err=0.407 loss=9.22e-03
 i= 208 alpha=0.189 err=0.406 loss=6.75e-03
 i= 224 alpha=0.181 err=0.411 loss=4.94e-03
 i= 240 alpha=0.197 err=0.403 loss=3.65e-03
 i= 256 alpha=0.194 err=0.404 loss=2.72e-03
 i= 272 alpha=0.192 err=0.405 loss=1.95e-03
 i= 288 alpha=0.197 err=0.403 loss=1.43e-03
 i= 304 alpha=0.197 err=0.403 loss=1.04e-03
 i= 320 alpha=0.198 err=0.402 loss=7.64e-04
 i= 336 alpha=0.210 err=0.397 loss=5.50e-04
 i= 352 alpha=0.223 err=0.390 loss=4.03e-04
 i= 368 alpha=0.173 err=0.414 loss=2.99e-04
 i= 384 alpha=0.192 err=0.405 loss=2.21e-04
 i= 400 alpha=0.175 err=0.413 loss=1.64e-04
 i= 416 alpha=0.206 err=0.399 loss=1.18e-04
 i= 432 alpha=0.186 err=0.408 loss=8.69e-05
 i= 448 alpha=0.195 err=0.404 loss=6.50e-05
 i= 464 alpha=0.205 err=0.399 loss=4.88e-05
 i= 480 alpha=0.194 err=0.404 loss=3.59e-05
 i= 496 alpha=0.194 err=0.404 loss=2.59e-05
 i= 512 alpha=0.190 err=0.406 loss=1.91e-05
 i= 528 alpha=0.210 err=0.397 loss=1.43e-05
 i= 544 alpha=0.201 err=0.401 loss=1.05e-05
 i= 560 alpha=0.187 err=0.407 loss=7.66e-06
 i= 576 alpha=0.212 err=0.396 loss=5.74e-06
 i= 592 alpha=0.192 err=0.405 loss=4.19e-06
 i= 608 alpha=0.187 err=0.408 loss=3.09e-06
 i= 624 alpha=0.187 err=0.408 loss=2.24e-06
 i= 640 alpha=0.209 err=0.397 loss=1.68e-06
 i= 656 alpha=0.171 err=0.415 loss=1.25e-06
 i= 672 alpha=0.212 err=0.396 loss=9.16e-07
 i= 688 alpha=0.199 err=0.402 loss=6.75e-07
 i= 704 alpha=0.181 err=0.411 loss=5.02e-07
 i= 720 alpha=0.187 err=0.407 loss=3.68e-07
 i= 736 alpha=0.185 err=0.409 loss=2.68e-07
 i= 752 alpha=0.191 err=0.405 loss=1.92e-07
 i= 768 alpha=0.200 err=0.401 loss=1.43e-07
 i= 784 alpha=0.214 err=0.394 loss=1.05e-07
 i= 800 alpha=0.192 err=0.405 loss=7.79e-08
 i= 816 alpha=0.206 err=0.398 loss=5.70e-08
 i= 832 alpha=0.194 err=0.404 loss=4.28e-08
 i= 848 alpha=0.190 err=0.406 loss=3.13e-08
 i= 864 alpha=0.194 err=0.404 loss=2.29e-08
 i= 880 alpha=0.188 err=0.407 loss=1.67e-08
 i= 896 alpha=0.208 err=0.397 loss=1.24e-08
 i= 912 alpha=0.221 err=0.391 loss=9.04e-09
 i= 928 alpha=0.195 err=0.404 loss=6.58e-09
 i= 944 alpha=0.206 err=0.399 loss=4.87e-09
 i= 960 alpha=0.195 err=0.404 loss=3.65e-09
 i= 976 alpha=0.195 err=0.404 loss=2.70e-09
 i= 992 alpha=0.196 err=0.403 loss=1.95e-09
 i=1008 alpha=0.199 err=0.402 loss=1.47e-09
 i=1024 alpha=0.184 err=0.409 loss=1.09e-09
 i=1040 alpha=0.202 err=0.400 loss=8.21e-10
 i=1056 alpha=0.190 err=0.406 loss=6.12e-10
 i=1072 alpha=0.189 err=0.407 loss=4.48e-10
 i=1088 alpha=0.185 err=0.408 loss=3.28e-10
 i=1104 alpha=0.217 err=0.393 loss=2.40e-10
 i=1120 alpha=0.186 err=0.408 loss=1.76e-10
 i=1136 alpha=0.215 err=0.394 loss=1.26e-10
 i=1152 alpha=0.202 err=0.400 loss=9.22e-11
 i=1168 alpha=0.193 err=0.405 loss=6.81e-11
 i=1184 alpha=0.179 err=0.411 loss=5.02e-11
 i=1200 alpha=0.210 err=0.397 loss=3.70e-11
 i=1216 alpha=0.233 err=0.386 loss=2.71e-11
 i=1232 alpha=0.198 err=0.402 loss=2.03e-11
 i=1248 alpha=0.208 err=0.397 loss=1.47e-11
 i=1264 alpha=0.183 err=0.409 loss=1.08e-11
 i=1280 alpha=0.202 err=0.401 loss=8.08e-12
 i=1296 alpha=0.220 err=0.392 loss=5.86e-12
 i=1312 alpha=0.194 err=0.404 loss=4.34e-12
 i=1328 alpha=0.196 err=0.403 loss=3.21e-12
 i=1344 alpha=0.200 err=0.401 loss=2.35e-12
 i=1360 alpha=0.195 err=0.404 loss=1.74e-12
 i=1376 alpha=0.193 err=0.405 loss=1.27e-12
 i=1392 alpha=0.176 err=0.413 loss=9.18e-13
 i=1408 alpha=0.180 err=0.411 loss=6.80e-13
 i=1424 alpha=0.201 err=0.401 loss=5.08e-13
 i=1440 alpha=0.186 err=0.408 loss=3.72e-13
 i=1456 alpha=0.197 err=0.403 loss=2.75e-13
 i=1472 alpha=0.191 err=0.406 loss=2.04e-13
 i=1488 alpha=0.172 err=0.415 loss=1.53e-13
 i=1504 alpha=0.201 err=0.401 loss=1.14e-13
 i=1520 alpha=0.195 err=0.404 loss=8.60e-14
 i=1536 alpha=0.201 err=0.401 loss=6.31e-14
 i=1552 alpha=0.209 err=0.397 loss=4.56e-14
 i=1568 alpha=0.178 err=0.412 loss=3.41e-14
 i=1584 alpha=0.193 err=0.405 loss=2.54e-14
 i=1600 alpha=0.187 err=0.408 loss=1.88e-14
 i=1616 alpha=0.222 err=0.391 loss=1.37e-14
 i=1632 alpha=0.197 err=0.403 loss=9.87e-15
 i=1648 alpha=0.194 err=0.404 loss=7.22e-15
 i=1664 alpha=0.190 err=0.406 loss=5.22e-15
 i=1680 alpha=0.174 err=0.414 loss=3.82e-15
 i=1696 alpha=0.198 err=0.402 loss=2.84e-15
 i=1712 alpha=0.198 err=0.402 loss=2.11e-15
 i=1728 alpha=0.207 err=0.398 loss=1.52e-15
 i=1744 alpha=0.210 err=0.396 loss=1.13e-15
 i=1760 alpha=0.196 err=0.403 loss=8.20e-16
 i=1776 alpha=0.183 err=0.410 loss=6.03e-16
 i=1792 alpha=0.172 err=0.415 loss=4.42e-16
 i=1808 alpha=0.201 err=0.401 loss=3.18e-16
 i=1824 alpha=0.210 err=0.396 loss=2.34e-16
 i=1840 alpha=0.208 err=0.397 loss=1.73e-16
 i=1856 alpha=0.186 err=0.408 loss=1.28e-16
 i=1872 alpha=0.185 err=0.409 loss=9.58e-17
 i=1888 alpha=0.188 err=0.407 loss=7.19e-17
 i=1904 alpha=0.170 err=0.416 loss=5.34e-17
 i=1920 alpha=0.191 err=0.406 loss=3.99e-17
 i=1936 alpha=0.180 err=0.411 loss=2.99e-17
 i=1952 alpha=0.197 err=0.403 loss=2.23e-17
 i=1968 alpha=0.204 err=0.400 loss=1.66e-17
 i=1984 alpha=0.202 err=0.400 loss=1.23e-17
 i=2000 alpha=0.184 err=0.409 loss=9.17e-18
 i=2016 alpha=0.209 err=0.397 loss=6.89e-18
 i=2032 alpha=0.178 err=0.412 loss=5.15e-18
 i=2048 alpha=0.200 err=0.401 loss=3.77e-18
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=10.1s).
Done training stage 3 (time=17s).
---------------------------------------------------------------------------
Done training (time=58s).
